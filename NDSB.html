<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Finlay Maguire" />
  <title>Casting a Deep Net: Classifying Plankton from Images</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="reveal.js/css/reveal.min.css"/>
    <style type="text/css">code{white-space: pre;}</style>
    <link rel="stylesheet" href="reveal.js/css/theme/simple.css" id="theme">
    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
      if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
      }
    </script>
    <!--[if lt IE 9]>
    <script src="reveal.js/lib/js/html5shiv.js"></script>
    <![endif]-->
    <script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Casting a Deep Net: Classifying Plankton from Images</h1>
    <h2 class="author">Finlay Maguire</h2>
    <h3 class="date">root@finlaymagui.re</h3>
</section>

<section id="overview" class="slide level2">
<h1>Overview</h1>
<ul>
<li>What?</li>
<li>Why?</li>
<li>Input data?</li>
<li>Solutions?</li>
<li>Performance?</li>
</ul>
</section>
<section><section id="what" class="titleslide slide level1"><h1>What?</h1></section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/NDSB.png" />
</figure>
<ul>
<li>90 days (December 15th 2014 - March 16th 2015)</li>
<li>Sponsored by Booz Allen Hamilton</li>
<li>Run by Kaggle</li>
<li>Hatfield Marine Science Center</li>
</ul>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/isiis.jpg" />
</figure>
<ul>
<li>In Situ Ichthyoplankton Imaging System</li>
<li>5 million shadowgraph images (4-5TB) a day</li>
<li>Automatically segmented</li>
<li>Manual analysis infeasible</li>
</ul>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/prob_dist.png" alt="Goal" /><figcaption>Goal</figcaption>
</figure>
<ul>
<li>Reliable automated identification of plankton</li>
<li>121 provided labels</li>
<li>Generate probability distribution for each image across labels</li>
</ul>
</section><section id="evaluation" class="slide level2">
<h1>Evaluation</h1>
<ul>
<li>multi-class logloss (cross-entropy loss or negative loglikelihood)</li>
</ul>
<p><span class="math">\[logloss = -\frac{1}{N} \sum_{i=1}^{N}\sum_{j=1}^{M}y_{ij} log(p_{ij})\]</span></p>
<ul>
<li>N is size of test set (20,000)</li>
<li>M is number of class labels (121)</li>
<li><span class="math">\(y_{ij}\)</span> is 1 if observation <span class="math">\(i\)</span> is in class <span class="math">\(j\)</span> and 0 otherwise.</li>
<li><span class="math">\(p_{ij}\)</span> is our predicted probability that <span class="math">\(i\)</span> belongs to <span class="math">\(j\)</span></li>
</ul>
</section><section id="evaluation-1" class="slide level2">
<h1>Evaluation</h1>
<ul>
<li>Sensitive to overconfidence</li>
<li>Differentiable</li>
<li>Not the same as accuracy (<span class="math">\(\frac{TP + TN}{TP + TN + FP + FN}\)</span>)</li>
<li>30:70 public:private test data split</li>
</ul>
</section></section>
<section><section id="why" class="titleslide slide level1"><h1>Why?</h1></section><section id="important-problem" class="slide level2">
<h1>Important problem</h1>
<ul>
<li>Ecological indicator of oceanic conditions</li>
<li>Ecosystem functions</li>
<li>Fishery monitoring</li>
<li>Allows autonomous remote monitoring</li>
</ul>
</section><section id="learning-opportunity" class="slide level2">
<h1>Learning opportunity</h1>
<ul>
<li>Machine learning practice</li>
<li>Collaborative coding practice</li>
<li>Playing with latest techniques</li>
<li>Fun</li>
<li>Instant feedback without data cleaning and gathering</li>
<li>...$100,000 1st Place Prize</li>
</ul>
</section></section>
<section><section id="input-data" class="titleslide slide level1"><h1>Input Data</h1></section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/raw_data.png" />
</figure>
</section><section class="slide level2">

<ul>
<li>30,336 labelled</li>
<li>20,000 unlabelled</li>
<li>121 classes</li>
<li>84-95% self-consistency in labelling [Culverhouse, 2003] (Dinoflagellates)</li>
<li>Scale invariant</li>
</ul>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/image_sizes.png" alt="Variable input size" /><figcaption>Variable input size</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/label_card.png" alt="Unbalanced classes" /><figcaption>Unbalanced classes</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/low_card.png" alt="Unbalanced classes" /><figcaption>Unbalanced classes</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/try_yourelf.png" alt="Classes very similar" /><figcaption>Classes very similar</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/raw_hierarchy.png" alt="Hierarchy of labels" /><figcaption>Hierarchy of labels</figcaption>
</figure>
</section></section>
<section><section id="making-the-most-of-this-data" class="titleslide slide level1"><h1>Making the most of this data</h1></section><section id="rescaling" class="slide level2">
<h1>Rescaling</h1>
<ul>
<li>Constant size</li>
<li>Makes life a lot easier</li>
<li>Makes training more stable</li>
<li>Lose detail (siamese network)</li>
<li>Lose sizing information (scale invariance)</li>
</ul>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/augmentation.png" alt="Get more data!" /><figcaption>Get more data!</figcaption>
</figure>
</section><section id="hierarchial-modelling" class="slide level2">
<h1>Hierarchial modelling</h1>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/raw_hierarchy.png" alt="Label schema" /><figcaption>Label schema</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/trees.png" alt="Left: Original Hiearchy, Right: New Layers" /><figcaption>Left: Original Hiearchy, Right: New Layers</figcaption>
</figure>
</section><section class="slide level2">

<ul>
<li>6 parallel softmax output layers</li>
<li>Improved initial learning rate</li>
<li>Logloss performance was unchanged</li>
</ul>
</section></section>
<section><section id="our-model" class="titleslide slide level1"><h1>Our Model</h1></section><section class="slide level2">

<ul>
<li>Two approaches</li>
<li>Classical Computer Vision e.g. BugID</li>
<li>Convoluted Neural Networks e.g. ImageNet</li>
<li>Combine best of all worlds</li>
</ul>
</section><section id="classical-computer-vision" class="slide level2">
<h1>Classical Computer Vision</h1>
<ul>
<li>More similar to classifiers explained</li>
<li>Apply specific functions to detect local features</li>
<li>General global image characteristics</li>
<li>Fit standard classifier RF, SVM, LR</li>
</ul>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/conv.jpg" alt="Convolution" /><figcaption>Convolution</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/convolution.png" alt="Convolution kernels" /><figcaption>Convolution kernels</figcaption>
</figure>
</section><section id="computer-vision-performance" class="slide level2">
<h1>Computer Vision Performance</h1>
<ul>
<li>Better with global rather than local features</li>
<li>Hiearchial label data made no difference</li>
<li>Slow, painstaking, manual</li>
<li>Worse than even simplest convnet</li>
</ul>
</section></section>
<section><section id="so-what-are-convnets" class="titleslide slide level1"><h1>So what are Convnets?</h1></section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/perceptron.png" alt="Artificial Neuron (from wikimedia)" /><figcaption>Artificial Neuron (from wikimedia)</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/ann.png" alt="Artificial Neural Network (from wikimedia)" /><figcaption>Artificial Neural Network (from wikimedia)</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/DNN.png" alt="Deep Neural Network (from neuralnetworksanddeeplearning.com)" /><figcaption>Deep Neural Network (from neuralnetworksanddeeplearning.com)</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/mylenet.png" alt="Convolutional Deep Neural Network: LeNet (from DeepLearning.net)" /><figcaption>Convolutional Deep Neural Network: LeNet (from DeepLearning.net)</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/arch.png" alt="Our architecture" /><figcaption>Our architecture</figcaption>
</figure>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/full_active.png" alt="Activation" /><figcaption>Activation</figcaption>
</figure>
</section></section>
<section><section id="combining-approaches" class="titleslide slide level1"><h1>Combining approaches</h1></section><section class="slide level2">

<ul>
<li>Integrated augmented CV-features with convnet</li>
<li>Added into network after convolutions</li>
<li>Decreased performance</li>
<li>Model averaging</li>
</ul>
</section></section>
<section><section id="how-did-we-do" class="titleslide slide level1"><h1>How did we do?</h1></section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/leader.png" />
</figure>
<ul>
<li>57/1,054 teams (5.4%)</li>
<li>Our LL and PPV = 0.704, 74.38%</li>
<li>Winner LL and PPV = 0.565, 81.52%</li>
<li>Very similar methodologies</li>
</ul>
</section><section id="so-what-did-the-winners-do-differently" class="slide level2">
<h1>So what did the winners do differently?</h1>
<ul>
<li>Everything we did but better!</li>
<li>More convolution layers with smaller kernels</li>
<li>Simultaneous cyclic pooling</li>
<li>Leaky rectified linear units</li>
</ul>
</section><section class="slide level2">

<figure>
<img src="assets/presentation/NDSB/cyclicpool.png" alt="Cyclic pooling" /><figcaption>Cyclic pooling</figcaption>
</figure>
</section></section>
<section><section id="conclusions" class="titleslide slide level1"><h1>Conclusions</h1></section><section class="slide level2">

<ul>
<li>Convnets are very powerful</li>
<li>However: implementation is non-trivial</li>
<li>Experiment with parameters individually</li>
<li>Unit testing your code is incredibly useful</li>
</ul>
</section><section id="acknowledgements" class="slide level2">
<h1>Acknowledgements</h1>
<p><em>University of Edinburgh Neuroinformatics DTC:</em></p>
<ul>
<li>Gavin Gray</li>
<li>Scott Lowe</li>
<li>Alina Selega</li>
<li>Matt Graham</li>
<li>Dragos Stanciu</li>
</ul>
</section><section id="citations" class="slide level2">
<h1>Citations</h1>
<ul>
<li>PF Culverhouse, Williams R, Reguera B, Herry V, González-Gil S. (2003) &quot;Do experts make mistakes? A comparison of human and machine identification of dinoflagellates.&quot; Mar. Ecol. Prog. Ser. 247:17-25.</li>
</ul>
</section></section>
    </div>
  </div>


  <script src="reveal.js/lib/js/head.min.js"></script>
  <script src="reveal.js/js/reveal.min.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        theme: 'moon', // available themes are in /css/theme
        transition: 'none', // default/cube/page/concave/zoom/linear/fade/none

        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: 'reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
//          { src: 'reveal.js/plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; }, }
//          { src: 'reveal.js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
]});
    </script>
    </body>
</html>
